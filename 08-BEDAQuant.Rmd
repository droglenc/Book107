# Bivariate EDA - Quantitative {#BEDAQuant}
Bivariate data occurs when two variables are measured on the same individuals. For example, you may measure (i) the height and weight of students in class, (ii) depth and area of a lake, (iii) gender and age of welfare recipients, or (iv) number of mice and biomass of legumes in fields. This module is focused on describing the bivariate relationship between two quantitative variables. Bivariate relationships between two categorical variables is described in Module \@ref(BEDACat).

Data on the weight (lbs) and highway miles per gallon (HMPG) for 93 cars from the 1993 model year are used as an example throughout this module. Ultimately, the relationship between highway MPG and the weight of a car is described. A sample of these data are shown below.

```{r CarData, echo=FALSE}
cars93 <- read.csv("https://raw.githubusercontent.com/droglenc/NCData/master/93cars.csv")
headtail(cars93,which=c("MFG","Model","Type","CMPG","HMPG","Weight","Cyls")) %>%
  knitr::kable(booktab=TRUE,row.names=FALSE,
               caption="Sample data from 1993 cars data set.") %>%
  kableExtra::kable_classic("hover",full_width=FALSE,html_font=khfont) %>%
  kableExtra::row_spec(0,bold=TRUE)
```

&nbsp;

## Response and Explanatory Variables
The **response variable** is the variable that one is interested in explaining something (i.e., variability) or in making future predictions about. The **explanatory variable** is the variable that may help explain or allow one to predict the response variable. In general, the response variable is thought to depend on the explanatory variable. Thus, the response variable is often called the **dependent variable**, whereas the explanatory variable is often called the **independent variable**.

One may identify the response variable by determining which of the two variables most likely depends on the other. For example, in the car data, highway MPG is the response variable because gas mileage is most likely affected by the weight of the car (e.g., hypothesize that heavier cars get worse gas mileage), rather than vice versa.

In some situations it is not obvious which variable is the response. For example, does the number of mice in the field depend on the number of legumes (lots of food=lots of mice) or the other way around (lots of mice=not much food left)? Similarly, does area depend on depth or does depth depend on area of the lake? In these situations, the context of the research question is needed to identify the response variable. For example, if the researcher hypothesized that number of mice will be greater if there are more legumes, then number of mice is the response variable. In many cases, the more difficult variable to measure will likely be the response variable. For example, researchers likely wish to predict area of a lake (hard to measure) from depth of the lake (easy to measure).

::: {.tip data-latex=''}
Which variable is the response may depend on the context of the research question.
:::

## Summaries
### Scatterplots
A scatterplot is a graph where each point simultaneously represents the values of both the quantitative response and quantitative explanatory variable. The value of the explanatory variable gives the x-coordinate and the value of the response variable gives the y-coordinate of the point plotted for an individual. For example, the first individual in the cars data is plotted at x (Weight) = `r cars93$Weight[1]` and y (HMPG) = `r cars93$HMPG[1]`, whereas the second individual is at x = `r cars93$Weight[2]` and y = `r cars93$HMPG[2]` (Figure \@ref(fig:carscat2)).

&nbsp;

```{r carscat2, echo=FALSE, fig.cap="Scatterplot between the highway MPG and weight of cars manufactured in 1993. For reference to the main text, the first individual is red and the second individual is blue."}
ggplot(data=cars93,mapping=aes(x=Weight,y=HMPG)) +
  geom_point(color="gray50",size=2) +
  geom_point(data=cars93[1,],color=clrs["red"],size=2) +
  geom_point(data=cars93[2,],color=clrs["blue"],size=2) +
  labs(x="Weight (lbs)",y="Highway MPG") +
  theme_NCStats()
```

### Correlation Coefficient
The sample correlation coefficient, abbreviated as r, is calculated with

$$ \text{r} = \frac{\sum_{\text{i}=1}^{n}\left[\left(\frac{\text{x}_{\text{i}}-\bar{\text{x}}}{\text{s}_{\text{x}}}\right)\left(\frac{\text{y}_{\text{i}}-\bar{\text{y}}}{\text{s}_{\text{y}}}\right)\right]}{\text{n}-1} $$

where s~x~ and s~y~ are the sample standard deviations for the explanatory and response variables, respectively.^[See Section \@ref(standard-deviation) for a review of standard deviations.] The formulae in the two sets of parentheses in the numerator are standardized values; thus, the value in each parenthesis is called the standardized x or standardized y, respectively. Using this terminology, the equation for r reduces to these steps:

1. For each individual, standardize x and standardize y.^[See Section \@ref(standardization-and-z-scores) for a review of standardized values.]
1. For each individual, find the product of the standardized x and standardized y.
1. Sum all of the products from step 2.
1. Divide the sum from step 3 by n-1.

Table \@ref(tab:corrCalc) illustrates these calculations for the first five individuals in the cars data.^[The five cars are treated as if they are the entire sample.] Note that the "i" column is an index for each individual, the x~i~ and y~i~ columns are the observed values of the two variables for individual i, $\bar{\text{x}}$ was computed by dividing the sum of the x~i~ column by n, s~x~ was computed by dividing the sum of the (x~i~-$\bar{\text{x}})$^2^ column by n-1 and taking the square root, and the "std x" column are the standardized x values found by dividing the values in the x~i~-$\bar{\text{x}}$ column by s~x~. Similar calculations were made for the y variable. The final correlation coefficient is the sum of the last column divided by n-1. Thus, the correlation between car weight and highway mpg for these five cars is `r formatC(corr(~HMPG+Weight,data=cars93[1:5,]),format="f",digits=2)`.

&nbsp;

```{r corrCalc, echo=FALSE}
tmp <- tibble(
  i=as.character(1:5),
  y=c(31,25,26,26,30),
  x=c(2705,3560,3375,3405,3640),
  ydiff=y-mean(y),
  xdiff=x-mean(x),
  ydiff2=ydiff^2,
  xdiff2=xdiff^2,
  ystd=ydiff/sd(y),
  xstd=xdiff/sd(x),
  prodstd=ystd*xstd
)
sums <- data.frame(i="Sum",matrix(colSums(tmp[,-1]),nrow=1))
names(sums) <- names(tmp)
tmp <- add_row(tmp,sums)
names(tmp) <- c("i","$\\text{y}_{\\text{i}}$","$\\text{x}_{\\text{i}}$","$\\text{y}_{\\text{i}}-\\bar{\\text{y}}$","$\\text{x}_{\\text{i}}-\\bar{\\text{x}}$","$(\\text{y}_{\\text{i}}-\\bar{\\text{y}})^{2}$","$(\\text{x}_{\\text{i}}-\\bar{\\text{x}})^{2}$","std. y","std. x","(std. y)(std. x)")

knitr::kable(tmp,booktab=TRUE,digits=c(0,1,1,2,2,2,0,3,3,3),
             caption="Demonstration of the calculation of r for a subsample of the car data.") %>%
  kableExtra::kable_classic("hover",full_width=FALSE,html_font=khfont) %>%
  kableExtra::row_spec(c(0,6),bold=TRUE) %>%
  kableExtra::row_spec(6,background="beige")
```

&nbsp;

The meaning and interpretation of r is discussed in more detail in the next section.


## Bivariate Items to Describe
Four characteristics should be described for a bivariate EDA with two quantitative variables:

* **form** of the relationship,
* presence (or absence) of **outliers**, and
* **association** or **direction** of the relationship,
* **strength** of the relationship.

All four of these items can be described from a scatterplot. However, for **linear** relationships, strength is best described from the correlation coefficient.

### Form and Outliers
The form of a relationship is determined by whether the "cloud" of points on a scatterplot forms a line or some sort of curve (Figure \@ref(fig:corrassn)). For the purposes of this introductory course, if the "cloud" appears linear then the form will be said to be linear, whereas if the "cloud" is curved then the form will be nonlinear. Scatterplots should be considered **linear** unless there is an OBVIOUS curvature in the points.

&nbsp;

```{r forms, echo=FALSE, fig.width=7.5,fig.height=2.5, fig.cap="Depictions of two linear and one nonlinear relationship. A smoother is shown to highlight the general form of the relationship."}
set.seed(1054)
tmp1 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,-0.9,-0.9,1),ncol=2)),
                   grp="Linear1")
tmp2 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0.4,0.4,1),ncol=2)),
                   grp="Linear2")
tmp3 <- tibble::tibble(X1=3*runif(100),
                       X2=2.5*(X1^2)-3*X1+rnorm(100,sd=1.5),
                       grp="Non-Linear")
tmp <- rbind(tmp1,tmp2,tmp3) %>%
  rename(x=X1,y=X2) %>%
  mutate(grp=factor(grp))

ggplot(data=tmp,mapping=aes(x=x,y=y)) +
  geom_smooth(se=FALSE,color=clrs["ltblue"]) +
  geom_point(shape=21,color="black",fill="darkgrey",size=2) +
  theme_NCStats() +
  theme(axis.title.x=element_blank(),axis.title.y=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        aspect.ratio=1) +
  facet_wrap(vars(grp),scale="free",
             labeller=labeller(grp=c("Linear1"="Linear","Linear2"="Linear",
                                   "Non-Linear"="Non-Linear")))
```

&nbsp;

An outlier is a point that is far removed from the main cluster of points (Figure \@ref(fig:outlier)). Keep in mind (as always) that just because a point is an outlier doesn't mean it is wrong.

&nbsp;

```{r outlier, echo=FALSE, fig.cap="Depiction of an outlier (red point) in an otherwise linear scatterplot."}
tmp1a <- rbind(tmp1[,1:2],c(X1=1.5,X2=3))
ggplot(data=tmp1a,mapping=aes(x=X1,y=X2)) +
  geom_point(shape=21,color="black",fill="darkgrey",size=2) +
  annotate(geom="point",x=1.5,y=3,pch=21,color="black",fill=clrs["red"],size=2) +
  theme_NCStats() +
  theme(axis.title.x=element_blank(),axis.title.y=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        aspect.ratio=1)
```

### Association or Direction
A positive association is when the scatterplot resembles an increasing function (i.e., increases from lower-left to upper-right; Figure \@ref(fig:corrassn)-Left). For a positive association, most of the individuals are above average or below average for both of the variables. A negative association is when the scatterplot looks like a decreasing function (i.e., decreases from upper-left to lower-right; Figure \@ref(fig:corrassn)-Right). For a negative association, most of the individuals are above average for one variable and below average for the other variable. No association is when the scatterplot looks like a "shotgun blast" of points (Figure \@ref(fig:corrassn)-Center). For no association, there is no tendency for individuals to be above or below average for one variable and above or below average for the other variable.

&nbsp;

```{r corrassn, echo=FALSE, fig.width=7.5,fig.height=2.5, fig.cap="Depiction of three types of association present in scatterplots. Dashed vertical lines are at the means of each variable."}
set.seed(1055)
tmp1 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0.8,0.8,1),ncol=2)),
                   grp="Positive")
tmp2 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0,0,1),ncol=2)),
                   grp="None")
tmp3 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,-0.7,-0.7,1),ncol=2)),
                   grp="Negative")
tmp <- rbind(tmp1,tmp2,tmp3) %>%
  rename(x=X1,y=X2) %>%
  mutate(grp=factor(grp,levels=c("Positive","None","Negative")),
         stdx=scale(x),stdy=scale(y),prod=stdx*stdy)

ggplot(data=tmp,mapping=aes(x=stdx,y=stdy)) +
  geom_vline(xintercept=0,color="gray80",linetype="dashed") +
  geom_hline(yintercept=0,color="gray80",linetype="dashed") +
  geom_smooth(se=FALSE,color=clrs["ltblue"]) +
  geom_point(shape=21,color="black",fill="darkgrey",size=2) +
  theme_NCStats() +
  theme(axis.title.x=element_blank(),axis.title.y=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        aspect.ratio=1) +
  facet_wrap(vars(grp),scale="free")
```

### Strength (and Association, Again)
Strength is a summary of how closely the points cluster around the general form of the relationship. For example, if a linear form exists, then strength is how closely the points cluster around the line. Strength is difficult to define from a scatterplot because it is a relative term. However, the correlation coefficient (r; Section \@ref(correlation-coefficient)) is a measure of strength and association between two variables, *if the form is linear*.

To better understand how r is a measure of association and strength, reconsider the steps in calculating r from Section \@ref(correlation-coefficient). The scatterplots in Figure \@ref(fig:corrdefn1) represent different associations. These scatterplots have dashed lines at the mean of both the x- and y-axis variables. Because the mean is subtracted from observed values when standardizing, points that fall above the mean will have positive standardized values and points that fall below the mean will have negative standardized values. The sign for the standardized values are depicted along the axes.

&nbsp;

```{r corrdefn1, echo=FALSE, fig.width=7.5,fig.height=2.5, fig.cap="Scatterplot with mean lines (dashed lines) and the signs of standardized values for both x and y shown for different associations. Blue points have a positive product of standardized values, whereas red points have a negative product of standardized values."}
ggplot(data=tmp,mapping=aes(x=stdx,y=stdy)) +
  geom_vline(xintercept=0,color="gray80",linetype="dashed") +
  geom_hline(yintercept=0,color="gray80",linetype="dashed") +
  geom_smooth(se=FALSE,color=clrs["ltblue"]) +
  geom_point(aes(fill=prod>0),shape=21,color="black",size=2) +
  scale_fill_manual(values=c(clrs[["ltred"]],clrs[["blue"]])) +
  scale_y_continuous(breaks=c(-1.5,1.5),labels=c("Below (-)","Above (+)")) +
  scale_x_continuous(breaks=c(-1.5,1.5),labels=c("Below (-)","Above (+)")) +
  theme_NCStats() +
  theme(axis.title.x=element_blank(),axis.title.y=element_blank(),
        axis.text.y=element_text(angle=90,hjust=0.5),
        axis.ticks=element_blank(),
        legend.position="none",
        aspect.ratio=1) +
  facet_wrap(vars(grp))
```

&nbsp;

Now consider the product of standardized x's and y's in each quadrant of the scatterplots in Figure \@ref(fig:corrdefn1). The product of standardized values is positive (blue points) in the quadrant where both standardized values are above average (i.e., both positive signs) and both are below average. The product of standardized values is negative (red points) in the other two quadrants.

Thus, for a positive association (Figure \@ref(fig:corrdefn1)-Left) the numerator of the correlation coefficient is positive because it is the sum of many positive (blue points) and few negative (red points) products of standardized values. Therefore, r for a positive association is positive (because the denominator of n-1 is always positive).  Conversely, for a negative association (Figure \@ref(fig:corrdefn1)-Right) the numerator of the correlation coefficient is negative because it is the sum of few positive (blue points) and many negative (red points) products of standardized values. Therefore, r for a negative association is negative.

Correlations range from -1 to 1. Absolute values of r equal to 1 indicate a perfect association (i.e., all points exactly on a line). A correlation of 0 indicates no association. Thus, absolute values of r near 1 indicate strong relationships and those near 0 are weak. How strength and association of the relationship change along the range of r values is illustrated in Figure \@ref(fig:corrstrength2). Guidelines in Table \@ref(tab:StrengthCriteria) can be used to convert values of r into words that describe the strength of relationship between two variables.

&nbsp;

```{r corrstrength2, echo=FALSE, fig.width=7, fig.cap="Scatterplots along the continuum of r values."}
set.seed(1909)
tmp1 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,1,1,1),ncol=2)),
                   dir="Positive",str="Strongest\n|r|=1")
tmp2 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0.8,0.8,1),ncol=2)),
                   dir="Positive",str="|r|=0.8")
tmp3 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0.4,0.4,1),ncol=2)),
                   dir="Positive",str="|r|=0.4")
tmp4 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0,0,1),ncol=2)),
                   dir="Positive",str="Weakest\nr=0")
tmp5 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,-1,-1,1),ncol=2)),
                   dir="Negative",str="Strongest\n|r|=1")
tmp6 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,-0.8,-0.8,1),ncol=2)),
                   dir="Negative",str="|r|=0.8")
tmp7 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,-0.4,-0.4,1),ncol=2)),
                   dir="Negative",str="|r|=0.4")
tmp8 <- data.frame(mvtnorm::rmvnorm(n=100,mean=c(0,0),
                                    sigma=matrix(c(1,0,0,1),ncol=2)),
                   dir="Negative",str="Weakest\nr=0")
tmp <- rbind(tmp1,tmp2,tmp3,tmp4,tmp5,tmp6,tmp7,tmp8) %>%
  rename(x=X1,y=X2) %>%
  mutate(dir=factor(dir,levels=c("Positive","Negative")),
         str=factor(str,levels=c("Strongest\n|r|=1","|r|=0.8",
                                 "|r|=0.4","Weakest\nr=0")),
         stdx=scale(x),stdy=scale(y),prod=stdx*stdy)

ggplot(data=tmp,mapping=aes(x=stdx,y=stdy)) +
  geom_vline(xintercept=0,color="gray80",linetype="dashed") +
  geom_hline(yintercept=0,color="gray80",linetype="dashed") +
  geom_smooth(se=FALSE,color=clrs["ltblue"]) +
  geom_point(aes(fill=prod>0),shape=21,color="black",size=2) +
  scale_fill_manual(values=c(clrs[["ltred"]],clrs[["blue"]])) +
  theme_NCStats() +
  theme(axis.title.x=element_blank(),axis.title.y=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        legend.position="none",
        aspect.ratio=1) +
  facet_grid(rows=vars(dir),cols=vars(str))
```

&nbsp;

```{r StrengthCriteria, echo=FALSE}
tmp <- tibble(strength=c("Strong","Moderate","Weak","None"),
              observational=c(">0.8",">0.6",">0.4","<0.4"),
              experimental=c(">0.98",">0.95",">0.9","<0.9"))
names(tmp) <- c("Statement","Observational (Uncontrolled)",
                "Experimental (Controlled)")
knitr::kable(tmp,booktab=TRUE,align="c",
             caption="Classifications of strength of relationship for absolute values of r by type of study.") %>%
  kableExtra::kable_classic("hover",full_width=FALSE,html_font=khfont) %>%
  kableExtra::row_spec(0,bold=TRUE) %>%
  kableExtra::column_spec(1:3,width="1.3in")
```

&nbsp;

## Example Interpretations
When performing a bivariate EDA for two quantitative variables, the form, presence (or absence) of outliers, association, and strength should be specifically addressed. In addition, you should state how you assessed strength. Specifically, you should use r to assess strength (see Section \@ref(strength-and-association-again)) **IF** the relationship is linear without any outliers. However, if the relationship is nonlinear, has outliers, or both, then strength should be subjectively assessed from the scatterplot.

Two other points should be considered when performing a bivariate EDA with quantitative variables. First, if outliers are present, do not let them completely influence your conclusions about form, association, and strength. In other words, assess these items ignoring the outlier(s). If you have raw data and the form excluding the outlier is linear, then compute r with the outlier eliminated from the data. Second, the form of weak relationships is difficult to describe because, by definition, there is very little clustering to a form. As a rule-of-thumb, if the scatterplot is not obviously curved, then it is described as linear by default.

::: {.tip data-latex=''}
* Outliers should not influence the descriptions of association, strength, and form.
* The form is linear unless there is an OBVIOUS curvature.
:::

Finally, in the examples below note that 1) form, outliers, association, and strength are specifically assessed in each; 2) strength is assessed from the correlation coefficient (and Table \@ref(tab:StrengthCriteria)) **only if the form is linear and there are no outliers**, 3) the position of outliers is specifically identified, and 4) how whether strength was assessed from the correlation coefficient or not was described.

### Highway MPG and Weight {-}

*The following overall bivariate summary for the relationship between highway MPG and weight is made using the scatterplot (Figure \@ref(fig:carscat2)) and correlation coefficient from the previous sections.*

The relationship between highway MPG and weight of cars appears to be slightly nonlinear (a slight concavity is apparent), negative, and moderately strong. The three points at (2400,46), (2500,27), and (1800,33) might be considered SLIGHT outliers (these are not far enough removed for me to consider them outliers, but some people may). The correlation coefficient was not used to assess strength because I deemed the relationship to be nonlinear.

### State Energy Usage {-}

> *A 2001 report from the [Energy Information Administration](http://www.eia.doe.gov/) of the Department of Energy details the total consumption of a variety of energy sources by state in 2001. Construct a proper EDA for the relationship between total petroleum and coal consumption (in trillions of BTU).*

```{r NRG1, echo=FALSE}
NRG <- read.csv("https://raw.githubusercontent.com/droglenc/NCData/master/NRG_Consump_2001.csv")
NRG1 <- NRG[-c(5,44),]
```
```{r scatNRG1, echo=FALSE, fig.width=7, fig.cap="Scatterplot of the total consumption of petroleum versus the consumption of coal (in trillions of BTU) by all 50 states and the District of Columbia. The points shown in the left with total petroleum values greater than 3000 trillion BTU are deleted in the right plot."}
p1 <- ggplot(data=NRG,mapping=aes(x=Coal,y=TotalPet)) +
  geom_point(pch=21,color="black",fill="darkgray",size=2) +
  labs(x="Coal Consumption (trillion BTU)",y="Total Petroleum (trillion BTU)") +
  theme_NCStats()
p2 <- p1 %+% NRG1 +
  annotate(geom="label",x=Inf,y=Inf,label="r = 0.53",vjust=1.3,hjust=1.1)
p1 + p2
```

&nbsp;

The relationship between total petroleum and coal consumption is generally linear, with two outliers at total petroleum levels greater than 3000 trillions of BTU, positive, and weak (Figure \@ref(fig:scatNRG1)-Left). I did not use the correlation coefficient because of the outliers. If the two outliers (Texas and California) are removed then the relationship is linear, with no additional outliers, positive, and weak (r=`r formatC(corr(~Coal+TotalPet,data=NRG1),format="f",digits=2)`) (Figure \@ref(fig:scatNRG1)-Right).

### Hatch Weight and Incubation Time of Geckos {-}

> *A [hobbyist](http://www.moonvalleyreptiles.com/breeding/incubation-length-and-hatch-weight) hypothesized that there would be a positive association between length of incubation (days) and hatchling weight (grams) for Crested Geckos (Rhacodactylus ciliatus). To test this hypothesis she collected the incubation time and weight for 21 hatchlings with the results shown below. Construct a proper EDA for the relationship between incubation time and hatchling weight.*

```{r scatGecko, echo=FALSE, fig.cap="Scatterplot of hatchling weight versus incubation time for Crested Geckos."}
df <- data.frame(inctime=c(53,54,56,60,60,60,60,60,63,63,77,
                           77,78,81,82,82,83,83,84,90,90),
                 hatchwt=c(1.5,1.7,1.4,1.0,1.4,1.5,1.7,1.8,
                           1.4,1.5,1.1,1.6,1.5,1.9,1.4,1.5,
                           1.3,1.7,1.6,1.4,1.8))
ggplot(data=df,mapping=aes(x=inctime,y=hatchwt)) +
  geom_point(pch=21,color="black",fill="darkgray",size=2) +
  labs(x="Incubation Time (days)",y="Hatchling Weight (grams)") +
  annotate(geom="label",x=-Inf,y=Inf,label="r = 0.11",vjust=1.3,hjust=-0.1) +
  theme_NCStats()
```

&nbsp;

The relationship between hatchling weight and incubation time for the Crested Geckos is linear, without obvious outliers (*though some may consider the small hatchling at 60 days to be an outlier*), without a definitive association, and weak (r=`r formatC(corr(~inctime+hatchwt,data=df),format="f",digits=2)`) (Figure \@ref(fig:scatGecko)). I did compute r because no outliers were present and the relationship was linear (or, at least, it was not nonlinear).


## Cautions About Correlation
Examining relationships between pairs of quantitative variables is common practice. Using r can be an important part of this analysis, as described above. However, r can be abused through misapplication and misinterpretation. Thus, it is important to remember the following characteristics of correlation coefficients:

* Variables must be quantitative (i.e., if you cannot make a scatterplot, then you cannot calculate r).
* The correlation coefficient only measures strength of **LINEAR** relationships (i.e., if the form of the relationship is not linear, then r is meaningless and should not be calculated).
* The units that the variables are measured in do not matter (i.e., r is the same between heights and weights measured in inches and lbs, inches and kg, m and kg, cm and kg, and cm and inches). This is because the variables are standardized when calculating r.
* The distinction between response and explanatory variables is not needed to compute r. That is, the correlation of GPA and ACT scores is the same as the correlation of ACT scores and GPA.
* Correlation coefficients are between -1 and 1.
* Correlation coefficients are strongly affected by outliers (simply, because both the mean and standard deviation, used in the calculation of r, are strongly affected by outliers).

Additionally, correlation is not causation! In other words, just because a strong correlation is observed it does not mean that the explanatory variable caused the response variable (an exception may be in carefully designed experiments). For example, it was found above that highway gas mileage decreased linearly as the weight of the car increased. One must be careful here to not state that increasing the weight of the car CAUSED a decrease in MPG because these data are part of an observational study and several other important variables were not considered in the analysis. For example, the scatterplot in Figure \@ref(fig:carscat3), coded for different numbers of cylinders in the car's engine, indicates that the number of cylinders may be inversely related to highway MPG and positively related to weight of the car. So, does the weight of the car, the number of cylinders, or both, explain the decrease in highway MPG?

&nbsp;

```{r carscat3, echo=FALSE, fig.cap="Scatterplot between the highway MPG and weight of cars manufactured in 1993 separated by number of cylinders."}
ggplot(data=filterD(cars93,!is.na(Cyls)),
                    mapping=aes(x=Weight,y=HMPG,fill=factor(Cyls))) +
  geom_point(pch=21,color="black",size=2) +
  labs(x="Weight (lbs)",y="Highway MPG",fill="# Cylinders") +
  theme_NCStats() +
  theme(legend.position=c(0.99,0.99),legend.justification=c(1,1),
        legend.key.size=unit(4,"mm"))
```

&nbsp;

More interesting examples that further demonstrate that "correlation is not causation" can be found on the [Spurious Correlations website](http://www.tylervigen.com/spurious-correlations) (e.g., high correlation between number of people who drowned by falling into a pool and the annual number of films that Nicolas Cage appeared in).

Finally, the word "correlation" is often misused in everyday language. "Correlation" should only be used when discussing the actual correlation coefficient (i.e., r). When discussing the association between two variables, one should use "association" or "relationship" rather than "correlation." For example, one might ask "What is the relationship between age and rate of cancer?", but should not ask (unless specifically interested in r) "What is the correlation between age and rate of cancer?".

&nbsp;
