[["index.html", "Readings for MTH107 Preface", " Readings for MTH107 Derek H. Ogle 02 Mar 2021 Preface This book contains a translation and re-development of past readings from MTH107. Thus, it contains all, but only, information that I expect you to know from this course. I have made every attempt to make it easy to read, provide visuals and explanations for all concepts, and grammatically correct. However, there are likely still errors or descriptions that dont make sense. Please feel free to ask questions or post errors on the appropriate channel of the course MS Team. The book highlights definitions and tips in special boxes. Definition: This is a definition. This is a tip. R Code and results are also shown in special boxes. Code in the R box can be copied verbatim from the box with the icon that appears when you hover over the upper right corner of the code box. dat &lt;- c(3,4,5,2,8) mean(dat) #R&gt; [1] 4.4 The material presented in this book can be challenging to master. Please dont hesitate to ask me questions as you have them! "],["chap-WhyStatsImportant.html", "Module 1 Why Statistics is Important 1.1 Realities 1.2 Major Goals of Statistics 1.3 Definition of Statistics 1.4 Why Does Statistics (as a tool) Exist?", " Module 1 Why Statistics is Important 1.1 Realities The city of Ashland performed an investigation in the area of Kreher Park (Figure 1.1) when considering the possible expansion of an existing wastewater treatment facility in 1989. The discovery of contamination from creosote waste in the subsoils and ground water at Kreher Park prompted the city to abandon the project. A subsequent assessment by the Wisconsin Department of Natural Resources (WDNR) indicated elevated levels of hazardous substances in soil borings, ground water samples, and in the sediments of Chequamegon Bay directly offshore of Kreher Park. In 1995 and 1999, the Northern States Power Company conducted investigations that further defined the area of contamination and confirmed the presence of specific contaminants associated with coal tar wastes. This site is now listed as a superfund site and is being given considerably more attention.1 Figure 1.1: Location of the Ashland superfund site (left) with the location of 119 historical sediment sampling sites (right). The WDNR wants to study elements in the sediment (among other things) in the entire 3000 m2 area shaded in Figure 1.1. Is it physically possible to examine every square meter of that area? Is it prudent, ecologically and economically, to examine every square meter of this area? The answer, of course, is no. How then will the WDNR be able to make conclusions about this entire area if they cannot reasonably examine the whole area? The most reasonable solution is to sample a subset of the area and use the results from this sample to make inferences about the entire area. Methods for properly selecting a sample that fairly represents a larger collection of individuals are an important area of study in statistics. For example, the WDNR would not want to sample areas that are only conveniently near shore because this will likely not be an accurate representation of the entire area. In this example, it appears that the WDNR used a grid to assure a relatively even dispersal of samples throughout the study area (Figure 1.1). Methods for choosing the number of individuals to select and how to select those individuals are discussed in Module 3. Suppose that the WDNR measured the concentration of lead at each of the 119 locations shown in Figure 1.1. Further suppose that they presented their results at a public meeting by simply showing the list of lead concentration measurements (Table 1.1).2 Is it easy to make conclusions about what these data mean from this type of presentation? Table 1.1: Lead concentration (\\(\\mu g \\cdot m^{-3}\\)) from 119 sites in Kreher Park superfund site. 0.91 1.09 1.00 1.09 1.06 0.98 0.98 0.94 0.89 1.09 0.91 1.06 0.81 0.90 1.21 1.03 0.95 1.14 0.99 0.99 0.96 1.13 0.84 1.03 0.86 0.98 1.04 0.91 1.27 0.90 0.87 1.23 1.12 0.98 0.79 1.10 1.06 1.09 0.73 0.81 1.18 0.92 0.82 1.11 0.97 1.24 1.06 1.09 0.78 0.94 1.08 0.91 0.98 1.22 1.04 0.77 1.18 0.93 1.14 0.94 1.05 0.91 1.14 0.93 0.94 0.90 1.05 1.36 1.02 0.93 1.09 1.17 0.91 1.06 0.95 0.88 0.67 1.12 1.06 0.99 0.89 0.83 0.99 1.33 1.00 1.05 1.11 1.01 1.25 0.96 1.07 1.17 1.01 1.20 1.17 1.05 1.21 1.10 1.07 1.01 1.16 1.24 0.86 0.90 1.07 1.11 0.99 0.70 0.98 1.11 1.12 1.30 1.00 0.89 0.91 0.95 1.08 1.02 0.93 Instead, suppose that the scientists brought a simple plot of the frequency of observed lead concentrations and brief numerical summaries (Figure 1.2) to the meeting. With these one can easily see that the measurements were fairly symmetric with no obviously weird values. The lead concentrations ranged from as low as 0.67 \\(\\mu g \\cdot m^{-3}\\) to as high as 1.36 \\(\\mu g \\cdot m^{-3}\\) with the measurements centered on approximately 1.0 \\(\\mu g \\cdot m^{-3}\\). These summaries are discussed in detail in Module ??. However, at this point, note that summarizing large quantities of data with few graphical or numerical summaries makes it is easier to identify meaning from data. Figure 1.2: Histogram and summary statistics of lead concentration measurements (\\(\\mu g \\cdot m^{-3}\\)) at each of 119 sites in Kreher Park superfund site. A critical question at this point is whether or not the results from the one sample of 119 sites perfectly represents the results for the entire area. One way to consider this question is to examine the results obtained from another sample of 119 sites. The results from this second sample (Figure 1.3) are clearly, though not radically, different from the results of the first sample. Thus, it is seen that any one sample from a larger whole will not perfectly represent the large whole. This will lead to some uncertainty in our summaries of the larger whole. Figure 1.3: Histogram and summary statistics of lead concentration measurements (\\(\\mu g \\cdot m^{-3}\\)) at each of 119 sites (different from the sites shown in Figure 1.2) in Kreher Park superfund site. The results from two different samples do not perfectly agree because each sample contains different individuals (sites in this example), and no two individuals are exactly alike. The fact that no two individuals are exactly alike is natural variability, because of the natural differences that occur among individuals. The fact that the results from different samples are different is called sampling variability. If there was no natural variability, then there would be no sampling variability. If there was no sampling variability, then the field of statistics would not be needed because a sample (even of one individual) would perfectly represent the larger group of individuals. Thus, understanding variability is at the core of statistical practice. Natural and sampling variability will be revisited continuously throughout this course. This may be unsettling! First, it was shown that an entire area or all of the individuals of interest cannot be examined. It was then shown that a sample of individuals from the larger whole did not perfectly represent the larger whole. Furthermore, each sample is unique and will likely lead to a (slightly) different conclusion. These are all real and difficult issues faced by the practicing scientist and considered by the informed consumer. However, the field of statistics is designed to deal with these issues such that the results from a relatively small subset of measurements can be used to make conclusions about the entire collection of measurements. Statistics provides methods for overcoming the difficulties caused by the requirement of sampling and the presence of sampling variability. 1.2 Major Goals of Statistics As seen in the Kreher Park example, the field of statistics has two primary purposes. First, statistics provides methods to summarize large quantities of data into concise and informative numerical or graphical summaries. For example, it was easier to discern the general underlying structure of the lead measurements from the statistics and histograms presented in Figures 1.2 and 1.3, than it was from the full list of lead measurements in Table 1.1. Second, statistical methods allow inferences to be made about all individuals (i.e., a population) from a few individuals (i.e., a sample).3 1.3 Definition of Statistics Statistics is the science of collecting, organizing, and interpreting numerical information or data (Moore and McCabe 1998). People study statistics for a variety of reasons, including (Bluman 2000): To understand the statistical studies performed in their field (i.e., be knowledgeable about the vocabulary, symbols, concepts, and statistical procedures used in those studies). To conduct research in their field (i.e., be able to design experiments and samples; collect, organize, analyze, and summarize data; make reliable predictions or forecasts for future use; and communicate statistical results). To be better consumers of statistical information. Statistics permeates a wide variety of disciplines. Moore and McCabe (1998) state: The study and collection of data are important in the work of many professions, so that training in the science of statistics is valuable preparation for a variety of careers. Each month, for example, government statistical offices release the latest numerical information on unemployment and inflation. Economists and financial advisers, as well as policy makers in government and business study these data in order to make informed decisions. Doctors must understand the origin and trustworthiness of the data that appear in medical journals if they are to offer their patients the most effective treatments. Politicians rely on data from polls of public opinion. Business decisions are based on market research data that reveal customer tastes. Farmers study data from field trials of new crop varieties. Engineers gather data on the quality and reliability of manufactured products. Most areas of academic study make use of numbers, and therefore also make use of the methods of statistics. 1.4 Why Does Statistics (as a tool) Exist? Besides demonstrating the two major goals of statistics, the Kreher Park example illustrates three realities that exist in nature and life that necessitate the need for statistics as tool for understanding. First, in most realistic situations it is not possible or, at least, not reasonable to see the entire population. For example, it was not reasonable to sample the sediments throughout the entire contaminated area near Kreher Park. In other examples, is it possible (or reasonable) to examine every Northern Short-Tailed Shew (Blarina bevicauda) in Great Lakes states, every person of legal voting age in Wisconsin, or every click on Facebook? Second, as described above, variability exists, both among individuals and results of samples. Third, because we must take samples from populations and those samples are both imperfect representations of the population and sampling variability exists, our conclusions about the population are uncertain. For example, the first sample in the Kreher Park example suggested that the mean lead concentration was 1.02 \\(\\mu g \\cdot m^{-3}\\), whereas the second sample was 0.98 \\(\\mu g \\cdot m^{-3}\\). You have also seen this concept when the margin-of-error in poll results are presented. In summary, statistics exist because we must sample instead of observe entire populations, variability is ever present, and the conclusions from samples are uncertain. More information at the EPA and the WDNR websites. These are hypothetical data for this site. Population and sample are defined more completely in Section @ref(chap:FoundationalDefns#IVPPSS). "],["chap-FoundationalDefinitions.html", "Module 2 Foundational Definitions 2.1 Definitions 2.2 Performing an IVPPSS 2.3 Variable Types", " Module 2 Foundational Definitions Statistical inference is the process of forming conclusions about a parameter of a population from statistics computed from individuals in a sample.4 Thus, understanding statistical inference requires understanding the difference between a population and a sample and a parameter and a statistic. And, to properly describe those items, the individual and variable(s) of interest must be identified. Understanding and identifying these six items is the focus of this module. The following hypothetical example is used throughout this module. Assume that we are interested in the average length of 1015 fish in Square Lake. To illustrate important concepts in this module, assume that all information for all 1015 fish in this lake is known (Figure 2.1). In real life this complete information would not be known. Figure 2.1: Schematic representation of individual fish (i.e., dots; Left) and histogram (Right) of the total length of the 1015 fish in Square Lake. 2.1 Definitions The individual in a statistical analysis is one of the items examined by the researcher. Sometimes the individual is a person, but it may be an animal, a piece of wood, a location, a particular time, or an event. It is extremely important that you dont always visualize a person when considering an individual in a statistical sense. Synonyms for individual are unit, experimental unit (usually used in experiments), sampling unit (usually used in observational studies), case, and subject (usually used in studies involving humans). An individual in the Square Lake example is a fish, because the researcher will collect a set of fish and examine each individual fish. The variable is the characteristic recorded about each individual. The variable in the Square Lake example is the length of each fish. In most studies, the researcher will record more than one variable. For example, the researcher may also record the fishs weight, sex, age, time of capture, and location of capture. In this module, only one variable is considered. In other modules, two variables will be considered. A population is ALL individuals of interest. In the Square Lake example, the population is all 1015 fish in the lake. The population should be defined as thoroughly as possible including qualifiers, especially those related to time and space, as necessary. This example is simple because Square Lake is so well defined; however, as you will see in the review exercises, the population is often only well-defined by your choice of descriptors. A parameter is a summary computed from ALL individuals in a population. The term for the particular summary is usually preceded by the word population. For example, the population average length of all 1015 fish in Square Lake is 98.06 mm and the population standard deviation is 31.49 mm (Table 2.1).5 Parameters are ultimately what is of interest, because interest is in all individuals in the population. However, in practice, parameters cannot be computed because the entire population cannot usually be seen. Table 2.1: Parameters for the total length of ALL 1015 fish in the Square Lake population. n mean sd min Q1 median Q3 max 1015 98.06 31.49 39 72 93 117 203 The entire population cannot beseen in real life. Thus, to learn something about the population, a subset of the population is usually examined. This subset is called a sample. The red dots in Figure 2.2 represent a random sample of n=50 fish from Square Lake (note that the sample size is usually denoted by n). Figure 2.2: Schematic representation (Left) of a sample of 50 fish (i.e., red dots) from Square Lake and histogram (Right) of the total length of the 50 fish in this sample. Summaries computed from individuals in a sample are called statistics. Specific names of statistics are preceded bysample. The statistic of interest is always the same as the parameter of interest; i.e., the statistic describes the sample in the same way that the parameter describes the population. For example, if interest is in the population mean, then the sample mean would be computed. Some statistics computed from the sample from Square Lake are shown in Table 2.2 and Figure 2.2. The sample mean of 107.5 mm is the bestguess at the population mean. Not surprisingly from the discussion in Module 1, the sample mean does not perfectly equal the population mean. Table 2.2: Summary statistics for the total length of a sample of 50 fish from the Square Lake population. n mean sd min Q1 median Q3 max 50 107.5 34.26 57 77.25 107.5 134.75 171 An individual is not necessarily a person. Populations and parameters can generally not beseen. 2.2 Performing an IVPPSS In each statistical analysis it is important that you determine the Individual, Variable, Population, Parameter, Sample, and Statistic (IVPPSS). First, determine what items you are actually going to look at; those are the individuals. Second, determine what is recorded about each individual; that is the variable. Third, ALL individuals is the population. Fourth, the summary (e.g., mean or proportion) of the variable recorded from ALL individuals in the population is the parameter.6 Fifth, the population usually cannot be seen, so only a few individuals are examined; those few individuals are the sample. Finally, the summary of the individuals in the sample is the statistic. When performing an IVPPSS, keep in mind that parameters describe populations (note that they both start withp) and statistics describe samples (note that they both start withs). This can also be looked at from another perspective. A sample is an estimate of the population and a statistic is an estimate of a parameter. Thus, the statistic has to be the same summary (mean or proportion) of the sample as the parameter is of the population. The IVPPSS process is illustrated for the following situation: A University of New Hampshire graduate student (and Northland College alum) investigated habitat utilization by New England (Sylvilagus transitionalis) and Eastern (Sylvilagus floridanus) cottontail rabbits in eastern Maine in 2007. In a preliminary portion of his research he determined the proportion of rabbit patches that were inhabited by New England cottontails. He examined 70 patches and found that 53 showed evidence of inhabitance by New England cottontails. An individual is a rabbit patch in eastern Maine in 2007 (i.e., a rabbit patch is the item being sampled and examined). The variable is evidence for New England cottontails or not (yes or no) (i.e., the characteristic of each rabbit patch that was recorded). The population is ALL rabbit patches in eastern Maine in 2007. The parameter is the proportion of ALL rabbit patches in eastern Maine in 2007 that showed evidence for New England cottontails.7 The sample is the 70 rabbit patches from eastern Maine in 2007 that were actually examined by the researcher. The statistic is the proportion of the 70 rabbit patches from eastern Maine in 2007 actually examined that showed evidence for New England cottontails. [In this case, the statistic would be 53/70 or 0.757.] In the descriptions above, take note that the individual is very carefully defined (including stating a specific time (2007) and place (eastern Maine)), the population and parameter both use the word ALL, the sample and statistic both use the specific sample size (70 rabbits), and that the parameter and statistics both use the same summary (i.e., proportion of patches that showed evidence of New England cottontails). In some situations it may be easier to identify the sample first. From this, and realizing that a sample is always of the individuals, it may be easier to identify the individual. This process is illustrated in the following example, with the items listed in the order identified rather than in the traditional IVPPSS order. The Duluth, MN Touristry Board is interested in the average number of raptors seen per year at Hawk Ridge.8 To determine this value, they collected the total number of raptors seen in a sample of years from 1971-2003. The sample is the 32 years between 1971 and 2003 at Hawk Ridge. An individual is a year (because a sample of years was taken) at Hawk Ridge. The variable recorded was the number of raptors seen in one year at Hawk Ridge. The population is ALL years at Hawk Ridge (this is a bit ambiguous but may be thought of as all years that Hawk Ridge has existed). The parameter is the average number of raptors seen per year in ALL years at Hawk Ridge. The statistic is the average number of raptors seen in the 1971-2003 sample of years at Hawk Ridge. Again, note that the individual is very carefully defined (including stating a specific time and place), the population and parameter both use the word ALL, the sample and statistic both use the specific sample size (32 years), and that the parameter and statistics both use the same summary (i.e., average number of raptors). An individual is usually defined by a specific time and place. Descriptions for population and parameter will always include the word All. Descriptions for sample and statistic will contain the specific sample size. Descriptions for parameter and statistic will contain the same summary (usually average/mean or proportion/percentage). Howeve the summary is for a different set of individuals  the population for the parameter and the sample for the statistic. 2.2.1 Sampling Variability (Revisited) It is instructive to once again (see Module 1) consider how statistics differ among samples. Table 2.3 and Figure 2.3 show results from three more samples of n=50 fish from the Square Lake population. The means from all four samples (including the sample in Table 2.2 and Figure 2.2) were quite different from the known population mean of 98.06 mm. Similarly, all four histograms were similar in appearance but slightly different in actual values. These results illustrate that a statistic (or sample) will only approximate the parameter (or population) and that statistics vary among samples. This sampling variability is one of the most important concepts in statistics and is discussed in great detail beginning in Module ??. Figure 2.3: Schematic representation (Left) of three samples of 50 fish (i.e., red dots) from Square Lake and histograms (Right) of the total length of the 50 fish in each sample. Table 2.3: Summary statistics for the total length in three samples of 50 fish from the Square Lake population. n mean sd min Q1 median Q3 max 2 50 100.48 31.87 45 78.25 99.5 120.00 180 3 50 99.40 38.28 47 69.00 90.5 113.75 203 4 50 98.14 32.26 45 71.25 87.0 121.50 174 Sampling Variability: The realization that no two samples are exactly alike. Thus, statistics computed from different samples will likely vary. This example also illustrates that parameters are fixed values because populations dont change. If a population does change, then it is considered a different population. In the Square Lake example, if a fish is removed from the lake, then the fish in the lake would be considered a different population. Statistics, on the other hand, vary depending on the sample because each sample consists of different individuals that vary (i.e., sampling variability exists because natural variability exists). Parameters are fixed in value, while statistics vary in value. 2.3 Variable Types The type of statistic that can be calculated is dictated by the type of variable recorded. For example, an average can only be calculated for quantitative variables (defined below). Thus, the type of variable should be identified immediately after performing an IVPPSS. 2.3.1 Variable Definitions There are two main groups of variable types  quantitative and categorical (Figure 2.4). Quantitative variables are variables with numerical values for which it makes sense to do arithmetic operations (like adding or averaging). Synonyms for quantitative are measurement or numerical. Categorical variables are variables that record which group or category an individual belongs. Synonyms for categorical are qualitative or attribute. Within each main type of variable are two subgroups (Figure 2.4). Figure 2.4: Schematic representation of the four types of variables. The two types of quantitative variables are continuous and discrete variables. Continuous variables are quantitative variables that have an uncountable number of values. In other words, a potential value does exist between every pair of values of a continuous variable. Discrete variables are quantitative variables that have a countable number of values. Stated differently, a potential value does not exist between every pair of values for a discrete variable. Typically, but not always, discrete variables are counts of items. Continuous and discrete variables are easily distinguished by determining if it is possible for a value to exist between every two values of the variable. For example, can there be between 2 and 3 ducks on a pond? No! Thus, the number of ducks is a discrete variable. Alternatively, can a duck weigh between 2 and 3 kg? Yes! Can it weigh between 2 and 2.1 kg? Yes! Can it weigh between 2 and 2.01 kg? Yes! You can see that this line of questions could continue forever; thus, duck weight is a continuous variable. A quantitative variable is continuous if a possible value exists between every two values of the variable; otherwise, it is discrete. The two types of categorical variables are ordinal and nominal. Ordinal variables are categorical variables where a natural order or ranking exists among the categories. Nominal variables are categorical variables where no order or ranking exists among the categories. Ordinal and nominal variables are easily distinguished by determining if the order of the categories matters. For example, suppose that a researcher recorded a subjective measure of condition (i.e., poor, average, excellent) and the species of each duck. Order matters with the condition variable  i.e., condition improves from the first (poor) to the last category (excellent)  and some reorderings of the categories would not make sense  i.e., average, poor, excellent does not make sense. Thus, condition is an ordinal variable. In contrast, species (e.g., mallard, redhead, canvasback, and wood duck) is a nominal variable because there is no inherent order among the categories (i.e., any reordering of the categories also makes sense). Ordinal means that an order among the categories exists (note ord in both ordinal and order). The following are some issues to consider when identifying the type of a variable: The categories of a categorical variable are sometimes labeled with numbers. For example, 1=Poor, 3=Fair, and 5=Good. Dont let this fool you into calling the variable quantitative. Rankings, ratings, and preferences are ordinal (categorical) variables. Counts of numbers are discrete (quantitative) variables. Measurements are typically continuous (quantitative) variables. It does not matter how precisely quantitative variables are recorded when deciding if the variable is continuous or discrete. For example, the weight of the duck might have been recorded to the nearest kg. However, this was just a choice that was made, the actual values can be continuously finer than kg and, thus, weight is a continuous variable. Categorical variables that consist of only two levels or categories will be labeled as a nominal variable (because any order of the groups makes sense). This type of variable is also often called binomial. Do not confuse what type of variable (answer is one of continuous, discrete, nominal, or ordinal) with what type of variability (answer is natural or sampling) questions. What type of variable is ? is a different question than what type of variability is ? Be careful to note the word difference (i.e., variable versus variability) when answering these questions. The precision to which a quantitative variable was recorded does not determine whether it is continuous or discrete. How precisely the variable COULD have been recorded is the important consideration. Formal methods of inference are discussed beginning with Module ??. We will discuss how to compute and interpret each of these values in later modules. Again, parameters generally cannot be computed because all of the individuals in the population can not be seen. Thus, the parameter is largely conceptual. Note that this population and parameter cannot actually be calculated but it is what the researcher wants to know. Information about Hawk Ridge is found here. "],["chap-DataProd.html", "Module 3 Data Production 3.1 Experiments 3.2 Observational Studies  Sampling", " Module 3 Data Production Statistical inference is the process} of making conclusions about a population from the results of a single sample. To make conclusions about the larger population, the sample must fairly represent the larger population. Thus, the proper collection (or production) of data is critical to statistics (and science in general). In this module, two ways of producing data  (1) Experiments and (2) Observational Studies  are described. Inferences cannot be made if data are not properly collected. 3.1 Experiments An experiment deliberately imposes a condition on individuals to observe the effect on the response variable. In a properly designed experiment, all variables that are not of interest are held constant, whereas the variable(s) that is (are) of interest are changed among treatments. As long as the experiment is designed properly (see below), differences among treatments are either due to the variable(s) that were deliberately changed or randomness (chance). Methods to determine if differences were likely due to randomness are developed in later modules. Because we can determine if differences most likely occurred o randomness or changes in the variales, strong cause-and-effect conclusions can be made from data collected from carefully designed experiments. 3.1.1 Single-factor Experiments A factor is a variable that is deliberately manipulated to determine its effect on the response variable. A factor is sometimes called an explanatory variable because we are attempting to determine how it affects (or explains) the response variable. The simplest experiment is a single-factor experiment where the individuals are split into groups defined by the categories of a single factor. For example, suppose that a researcher wants to examine the effect of temperature on the total number of bacterial cells after two weeks. They have inoculated 120 agars9 with the bacteria and placed them in a chamber where all environmental conditions (e.g., temperature, humidity, light) are controlled exactly. The researchers will use only two temperatures in this simple experiment  10oC and 15oC. All other variables are maintained at constant levels. Thus, temperature is the only factor in this simple experiement because it is the only variable manipulated to different values to determine its impact on the number of bacterial cells. In a single-factor experiment only one explanatory variable (i.e., factor) is allowed to vary; all other explanatory variables are held constant. Levels are the number of categories of the factor variable. In this example, there are two levels  10oC and 15oC. Treatments are the number of unique conditions that individuals in the experiment are exposed to. In a single-factor experiment, the number of treatments is the same as the number of levels of the single factor. Thus, in this simple experiment, there are two treatments  10oC and 15oC. Treatments are discussed more thoroughly in the next section. The number of replicates in an experiment is the number of individuals that will receive each treatment. In this example, a replicate is an inoculated agar. The number of replicates is the number of inoculated agars that will receive each of the two temperature treatments. The number of replicates is determined by dividing the total number of available individuals (120) by the number of treatments (2). Thus, in this example, the number of replicates is 60 inoculated agars. The agars used in this experiment will be randomly allocated to the two temperature treatments. All other variables  humidity, light, etc.  are kept the same for each treatment. At the end of two weeks, the total number of bacterial cells on each agar (i.e., the response variable) will be recorded and compared between the agars kept at both temperatures.10 Any difference in mean number of bacterial cells will be due to either different temperature treatments or randomness, because all other variables were the same between the two treatments. Differences among treatments are either caused by randomness (chance) or the factor. The single factor is not restricted to just two levels. For example, more than two temperatures, say 10oC, 12.5oC, 15oC, and 17.5oC, could have been tested. With this modification, there is still only one factor  temperature  but there are now four levels (and only four treatments). 3.1.2 Multi-factor Experiments  Design and Definitions More than one factor can be tested in an experiment. In fact, it is more efficient to have a properly designed experiment where more than one factor is varied at a time than it is to use separate experiments in which only one factor is varied in each. However, before showing this benefit, lets examine the definitions from the previous section in a multi-factor experiment. Suppose that the previous experiment was modified to also examine the effect of relative humidity on the number of bacteria cells. This modified experiment has two factors  temperature (with two levels of 10oC or 15oC) and relative humidity (with four levels of 20%, 40%, 60%, and 80%). The number of treatments, or combinations of all factors, in this experiment is found by multiplying the levels of all factors (i.e., 2×4=8 in this case). The number of replicates in this experiment is now 15 (i.e., total number of available agars divided by the number of treatments; 120/8). The number of treatments is determined for the overall experiment, whereas the number of levels is determined for each factor. A drawing of the experimental design can be instructive (Table 3.1). The drawing is a table where the levels of one factor are shown in the rows of the first column and the levels of the other factor are shown in the rows of the second column such that each level of the first facor is matched with one of the levels of the second factor. With this, the number of rows in the table is the number of treatments in the experiment. I also like to include a column that lists the number of replicates in each treatment and the individual randomly allocated to each treatment (how to randomly allocate individuals to treatments is shown in the Allocating Individuals section below). Table 3.1: Diagram of a two-factor experiment with temperature and relative humidity. Temp. Rel. Hum. # Reps Agars 10oC 20% 15 79, 78, 14, 63, 41, 115, 107, 59, 35, 110, 8, 46, 64, 99, 37 10oC 40% 15 38, 81, 48, 74, 36, 77, 95, 65, 91, 26, 98, 1, 97, 108, 62 10oC 60% 15 39, 42, 82, 47, 101, 106, 29, 113, 2, 53, 18, 32, 52, 34, 117 10oC 80% 15 100, 43, 75, 116, 67, 54, 10, 102, 16, 92, 88, 40, 17, 96, 33 15oC 20% 15 87, 70, 13, 111, 89, 85, 80, 83, 112, 86, 6, 19, 21, 84, 93 15oC 40% 15 12, 45, 66, 31, 30, 22, 90, 72, 7, 120, 27, 50, 23, 71, 69 15oC 60% 15 25, 103, 109, 94, 15, 55, 58, 61, 60, 56, 11, 57, 73, 44, 119 15oC 80% 15 104, 68, 20, 51, 24, 5, 114, 4, 28, 118, 105, 76, 9, 3, 49 3.1.3 Multi-factor Experiments  Benefits The analysis of a multi-factor experimental design is more involved than what will be shown in this course. However, multi-factor experiments have many benefits, which can be illustrated by comparing a multi-factor experiment to separate single-factor experiments. For example, in addition to the two factor experiment in the previous section, consider separate single-factor experiments to determine the effect of each factor separately (further assume that individuals (i.e., agars) can be used in only one of these separate experiments). To conduct the two separate experiments, randomly split the 120 available agars into two equally-sized groups of 60. The first 60 will be split into two groups of 30 for the first experiment with two temperatures. The second 60 will be split into four groups of 15 for the second experiment with four relative humidities. These separate single-factor experiments are summarized in Table 3.2. Table 3.2: Diagram of two one-factor-at-a-time experiments with temperature (Top) and relative humidity (Bottom). Temp. # Reps Agars 10oC 30 79, 78, 14, 63, 41, 115, 107, 59, 35, 110 ,  15oC 30 39, 42, 82, 47, 101, 106, 29, 113, 2, 53 ,  Rel. Hum. # Reps Agars 20% 15 87, 70, 13, 111, 89, 85, 80, 83, 112, 86, 6, 19, 21, 84, 93 40% 15 12, 45, 66, 31, 30, 22, 90, 72, 7, 120, 27, 50, 23, 71, 69 60% 15 25, 103, 109, 94, 15, 55, 58, 61, 60, 56, 11, 57, 73, 44, 119 80% 15 104, 68, 20, 51, 24, 5, 114, 4, 28, 118, 105, 76, 9, 3, 49 The key to examining the benefits of the multi-factor experiment is to determine the number of individuals that give information about (i.e., are exposed to) each factor. In the two-factor experiment all 120 individuals were exposed to one of the temperature levels with 60 individuals exposed to each level (Table 3.1). In contrast, only 30 individuals were exposed to these levels in the single-factor experiment (Table 3.2-Top). In addition, in the two-factor experiment all 120 individuals were exposed to one of the relative humidity levels with 30 individuals exposed to each level (Table 3.1). Again, this is in contrast to the single-factor experiment where only 15 individuals were exposed to these levels (Table 3.2-Bottom). Thus, the first advantage of multi-factor experiments is that the available individuals are used more efficiently. In other words, more information (i.e., the responses of more individuals) is obtained from a multi-factor experiment than from combinations of single-factor experiments.11 A properly designed multi-factor experiment also allows researchers to determine if multiple factors interact to impact an individuals response. For example, consider the hypothetical results from this experiment in Figure 3.1-Left.12 The effect of relative humidity is to increase the growth rate for those individuals at 10oC (black line) but to decrease the growth rate for those individuals at 15oC (blue line). That is, the effect of relative humidity differs depending on the level of temperature. When the effect of one factor differs depending on the level of the other factor, then the two factors are said to interact. Interactions cannot be determined from the two single-factor experiments because the same individuals are not exposed to levels of the two factors at the same time. Figure 3.1: Mean growth rates in a two-factor experiment that depict an interaction effect (left) and no interaction effect (right). Multi-factor experiments are used to detect the presence or absence of interaction, not just the presence of it. The hypothetical results in Figure 3.1-Right show that the growth rate increases with increasing relative humidity at about the same rate for both temperatures. Thus, because the effect of relative humidity is the same for each temperature (and vice versa), there does not appear to be an interaction between the two factors. Again, this could not be determined from the separate single-factor experiments. 3.1.4 Allocating Individuals Individuals13 should be randomly allocated (i.e., placed into) to treatments. Randomization will tend to even out differences among groups for variables not considered in the experiment. In other words, randomization should help assure that all groups are similar before the treatments are imposed. Thus, randomly allocating individuals to treatments removes any bias (foreseen or unforeseen) from entering the experiment. In the single-factor experiment above  two treatments of temperature  there were 120 agars. To randomly allocate these individuals to the treatments, 60 pieces of paper marked with 10 and 60 marked with 15 could be placed into a hat. One piece of paper would be drawn for each agar and the agar would receive the temperature found on the piece of paper. Alternatively, each agar could be assigned a unique number between 1 and 120 and pieces of paper with these numbers could be placed into the hat. Agars corresponding to the first 60 numbers drawn from the hat could then be placed into the first treatment. Agars for the next (or remaining) 60 numbers would be placed in the second treatment. This process is essentially the same as randomly ordering 120 numbers. A random order of numbers is obtained with R by including the count of numbers as the only argument to sample(). For example, randomly ordering 1 through 120 is accomplished with sample(120) #R&gt; [1] 79 78 14 63 41 115 107 59 35 110 8 46 64 99 37 38 81 48 #R&gt; [19] 74 36 77 95 65 91 26 98 1 97 108 62 39 42 82 47 101 106 #R&gt; [37] 29 113 2 53 18 32 52 34 117 100 43 75 116 67 54 10 102 16 #R&gt; [55] 92 88 40 17 96 33 87 70 13 111 89 85 80 83 112 86 6 19 #R&gt; [73] 21 84 93 12 45 66 31 30 22 90 72 7 120 27 50 23 71 69 #R&gt; [91] 25 103 109 94 15 55 58 61 60 56 11 57 73 44 119 104 68 20 #R&gt; [109] 51 24 5 114 4 28 118 105 76 9 3 49 Thus, the first five (of 60) agars in the 10oC treatment are 79, 78, 14, 63, and 41 (Table 3.2-Top). The first five (of 60) agars in the 15oC treatment are 87, 70, 13, 111, and 89 (Table 3.2-Top). In the modified experiment with two factors  temperature and relative humidity  with eight treatments containing 15 agars each, the random numbers would be divided into 8 groups each with 15 numbers. The allocation of individuals was shown in Table 3.1. Individuals should be randomly allocated to treatments to remove bias. 3.1.5 Design Principles There are many other methods of designing experiments and allocating individuals that are beyond the scope of this book.14 However, all experimental designs contain the following three basic principles. Control the effect of variables on the response variable by deliberately manipulating factors to certain levels and maintaining constancy among other variables. Randomize the allocation of individuals to treatments to eliminate bias. Replicate individuals (use many individuals) in the experiment to reduce chance variation in the results. Proper control in an experiment allows for strong cause-and-effect conclusions to be made (i.e., to state that an observed difference in the response variable was due to the levels of the factor or chance variation rather than some other foreseen or unforeseen variable). Randomly allocating individuals to treatments removes any bias that may be included in the experiment. For example, if we do not randomly allocate the agars to the treatments, then it is possible that a set of all poor agars may end up in one treatment. In this case, any observed differences in the response may not be due to the levels of the factor but to the prior quality of the agars. Replication means that there should be more than one or a few individuals in each treatment. This reduces the effect of each individual on the overall results. For example, if there was one agar in each treatment, then, even with random allocation, the effect of that treatment may be due to some inherent properties of that agar rather than the levels of the factors. Replication, along with randomization, helps assure that the groups of individuals in each treatment are as alike as possible at the start of the experiment. 3.2 Observational Studies  Sampling In observational studies the researcher has no control over any of the variables observed for an individual. The researcher simply observes individuals, disturbing them as little as possible, trying to get a picture of the population. Observational studies cannot be used to make cause-and-effect statements because all variables that may impact the outcome may not have been measured or specifically controlled. Thus, any observed difference among groups may be caused by the variables measured, some other unmeasured variables, or chance (randomness). Consider the following as an example of the problems that can occur when all variables are not measured. For many years scientists thought that the brains of females weighed less than the brains of males. They used this finding to support all kinds of ideas about sex-based differences in learning ability. However, these earlier researchers failed to measure body weight, which is strongly related to brain weight in both males and females. After controlling for the effect of differences in body weights, there was no difference in brain weights between the sexes. Thus, many sexist ideas persisted for years because cause-and-effect statements were inferred from data where all variables were not considered. Strong cause-and-effect statements CANNOT be made from observational studies. In observational studies, it is important to understand to which population inferences will refer.15 To make useful inferences from a sample, the sample must be an unbiased representation of the population. In other words, it must not systematically favor certain individuals or outcomes. For example, consider that you want to determine the mean length of all fish in a particular lake (e.g., Square Lake from Module 2). Using a net with large mesh, such that only large fish are caught, would produce a biased sample because interest is in all fish not just the large fish. Setting the nets near spawning beds (i.e., only adult fish) would also produce a biased sample. In both instances, a sample would be collected from a population other than the population of interest. Thus it is important to select a sample from the specified population. It is important to understand the population before considering how to take a sample. 3.2.1 Types of Sampling Designs Three common types of sampling designs  voluntary response, convenience, and probability-based samples  are considered in this section. Voluntary response and convenience samples tend to produce biased samples, whereas proper probability-based samples will produce an unbiased sample. A voluntary response sample consists of individuals that have chosen themselves for the sample by responding to a general appeal. An example of a voluntary response sample would be the group of people that respond to a general appeal placed in the school newspaper. If the population of interest in this sample was all students at the school, then this type of general appeal would likely produce a biased sample of students that (i) read the school newspaper, (ii) feel strongly about the topic, or (iii) both. A convenience sample consists of individuals who are easiest to reach for the researcher. An example of a convenience sample is when a researcher queries only those students in a particular class. This sample is convenient because the individuals are easy to gather. However, if the population of interest was all students at the school, then this type of sample would likely produce a biased sample of students that is likely of (i) one major or another, (ii) one or a few years-in-school (e.g., Freshman or Sophomores), or (iii) both. In probability-based sampling, each individual of the population has a known chance of being selected for the sample. The simplest probability-based sample is the Simple Random Sample (SRS) where each individual has the same chance of being selected. Proper selection of an SRS requires each individual to be assigned a unique number. The SRS is then formed by choosing random numbers and collecting the individuals that correspond to those numbers. For example, an auditor may need to select a sample of 30 financial transactions from all transactions of a particular bank during the previous month. Because each transaction is numbered, the auditor may know that there were 1112 transactions during the previous month (i.e., the population). The auditor would then number each transaction from 1 to 1112, randomly select 30 numbers (with no repeats) from between 1 and 1112, and then physically locate the 30 transactions that correspond to the 30 selected numbers. Those 30 transactions are the SRS. Random numbers are selected in R by including the population size as the first and sample size as the second argument to sample(). For example, 30 numbers from between 1 and 1112 is selected with sample(1112,30) #R&gt; [1] 684 986 155 638 10 390 381 265 474 707 699 97 752 681 565 #R&gt; [16] 739 59 324 861 637 490 911 446 406 846 516 269 1052 384 1105 Thus, accounts 684, 986, 155, 638, and 10 would be the first five (of 30) selected. There are other more complex types of probability-based samples that are beyond the scope of this course.16 However, the goal of these more complex types of samples is generally to impart more control into the sampling design. A proper SRS requires each individual i the population to be assigned a unique number. If the population is such that a number cannot be assigned to each individual, then the researcher must try to use a method for which they feel each individual has an equal chance of being selected. Usually this means randomizing the technique rather than the individuals. In the fish example discussed on the previous page, the researcher may consider choosing random mesh sizes, random locations for placing the net, or random times for placing the net. Thus, in many real-life instances, the researcher simply tries to use a method that is likely to produce an SRS or something very close to it. If a number cannot be assigned to each individual in the population, then the researcher should randomize the technique to assure as close to a random sample as possible. Polls, campaign or otherwise, are examples of observational studies that you are probably familiar with. The following are links where various aspects of polling are discussed. How Polls are Conducted by Frank Newport, Lydia Saad, and David Moore, The Gallup Organization. Why Do Campaign Polls Zigzag So Much? by G.S. Wasserman, Purdue U. 3.2.2 Of What Value are Observational Studies? Properly designed experiments can lead to cause-and-effect statements, whereas observational studies (even properly designed) are unlikely to lead to such statements. Furthermore, in the last section, it was suggested that it is very difficult to take a proper probability-based sample because it is hard to assign a number to each individual in the population (precisely because entire populations are very difficult to see). So, do observational studies have any value? There are at least three reasons why observational studies are useful. The scientific method begins with making an observation about a natural phenomenon. Observational studies may serve to provide such an observation. Alternatively, observational studies may be deployed after an observation has been made to see if that observation is prevalent and worthy of further investigation. Thus, observational studies may lead directly to hypotheses that form the basis of experiments. Experiments are often conducted under very confined and controlled conditions so that the effect of one or more factors on the response variable can be identified. However, at the conclusion of an experiment it is often questioned whether a similar response would be observed in nature under much less controlled conditions. For example, one might determine that a certain fertilizer increases growth of a certain plant in the greenhouse, with consistent soil characteristics, temperatures, lighting, etc. However, it is a much different, and, perhaps, more interesting, question to determine if that fertilizer elicits the same response when applied to an actual field. Finally, there are situations where conducting an experiment simply cannot be done, either for ethical, financial, size, or other constraints. For example, it is generally accepted that smoking causes cancer in humans even though an experiment where one group of people was forced to smoke while another was not allowed to smoke has not been conducted. Similarly, it is also very difficult to perform valid experiments on ecosystems. In these situations, an observational study is simply the best study allowable. Cause-and-effect statements are arrived at in these situations because observational studies can be conducted with some, though not absolute, control and control can be imparted mathematically into some analyses.17 In addition, a preponderance of evidence may be arrived at if enough observational studies point to the same conclusion. An agar, in this case, is a petri dish with a growth medium for the bacteria. Methods for making this comparison are in Module ??. The real importance of this advantage will become apparent when statistical power is introduced in Module ??. The means of each treatment are plotted and connected with lines in this plot. When discussing experiments, an individual is often referred to as a replicate or an experimental unit. Other common designs include blocked, Latin square, and nested designs. Thus, it is very important to first perform an IVPPS as discussed in Module 2. For example, stratified samples, nested, and multistage samples. These analyses are beyond the scope of this book, though. "],["references.html", "References", " References "]]
